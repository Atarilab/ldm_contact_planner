{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa992893-5fe7-40ac-b3ff-6241c8b34781",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b18263f2-b5f4-4c26-bdee-07e6232f01b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import MllamaForConditionalGeneration, AutoProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f426de8-bbdf-45fc-86e1-3c3ee140bbb9",
   "metadata": {},
   "source": [
    "# Llama 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d03ccd-0f95-4e8f-82c6-adf6b624594a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c29900a095bf475eb4c849953d54ddb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-11B-Vision-Instruct\"\n",
    "\n",
    "model = MllamaForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97f705ff-606b-40cc-a3ee-ed6c37203a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Objects in the Image:**\n",
      "\n",
      "*   Blue Table: [(0.07, 0.06), (0.93, 0.44)]\n",
      "*   Green Cube: [(0.32, 0.57), (0.73, 0.79)]\n",
      "*   Brown Floor Tiles: [(0.00, 0.00), (1.00, 0.98)]<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "image = Image.open(\"/home/ilyass/reference3.png\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"image\"},\n",
    "        {\"type\": \"text\", \"text\": \"Give me the list of the objects present in the image their respective upper-left and bottom-right corners of the bounding box relative to the image size using this format [(object_name, upper-left corner, bottom-right corner)]\"}\n",
    "    ]}\n",
    "]\n",
    "input_text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = processor(image, input_text, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "output = model.generate(**inputs, max_new_tokens=1e6)\n",
    "print(processor.decode(output[0][inputs[\"input_ids\"].shape[-1]:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f0a2a78-50d3-482d-b53c-af20c7b6c85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To place the green cube on top of the table, a person should perform the following actions:\n",
      "\n",
      "1. Pick the green cube.\n",
      "2. Move the green cube to the table.\n",
      "3. Place the green cube on top of the table.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "image = Image.open(\"/home/ilyass/reference3.png\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"image\"},\n",
    "        {\"type\": \"text\", \"text\": \"Given the image, what are the sequence of actions a person should perform to place the green cube on top of the table? Your answers should have a format similar to <verb> + <determinant> + <object>, for example 'pick the mugh' .\"}\n",
    "    ]}\n",
    "]\n",
    "input_text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = processor(image, input_text, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "output = model.generate(**inputs, max_new_tokens=1e6)\n",
    "print(processor.decode(output[0][inputs[\"input_ids\"].shape[-1]:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b73a7ea-bea3-4b86-b788-4d2c206d5bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(processor.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d6ee88d-339a-4b67-a634-e1561827819c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_gpu():\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "213400c7-9064-444d-a6b7-2094a464ae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_gpu()\n",
    "del input_text, inputs, output\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aaac55a-9e04-4262-bfd7-3afbd4c0e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"/home/ilyass/Pictures/Screenshots/reference.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a2a5ec8-cfa7-47f0-8ece-b19051374452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670.15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.width * 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "989b9e7a-e289-42f7-8b83-5ee2e495d33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "507.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.height * 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f39d1c-53f6-4665-96a1-3ee075182431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
