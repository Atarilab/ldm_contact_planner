{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb6a261-d9bd-451e-a44f-4c163817b060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.spatial.transform import Rotation as R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0f25cf4-fc89-4560-b4ae-cf625881c03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_3d_correspondences(source_points: list, target_point: tuple, depth: list, K: list, max_distance = 3):\n",
    "    source_points_3d = []\n",
    "    target_points_3d = []\n",
    "\n",
    "    # Lift first source point and respective target point\n",
    "    source_points_3d.append(project_2d_to_3d(source_points[0], K[0], depth[0][source_points[0][::-1]]))\n",
    "    target_points_3d.append(project_2d_to_3d(target_point, K[1], depth[1][target_point[::-1]]))\n",
    "\n",
    "    # For the other source points sample points around the target point\n",
    "    sampled_points, already_sampled_points = [], set()\n",
    "    \n",
    "    while len(sampled_points) < len(source_points) - 1:\n",
    "        # Random distance from center (uniformly between 0 and max_distance)\n",
    "        distance = np.random.uniform(0, max_distance)\n",
    "        \n",
    "        # Random angle in radians\n",
    "        angle = np.random.uniform(0, 2 * np.pi)\n",
    "        \n",
    "        # Convert polar coordinates (distance, angle) to Cartesian coordinates\n",
    "        x = target_point[0] + distance * np.cos(angle)\n",
    "        y = target_point[1] + distance * np.sin(angle)\n",
    "\n",
    "        if (x, y) not in already_sampled_points:\n",
    "            sampled_points.append((int(x), int(y)))\n",
    "            already_sampled_points.add((int(x), int(y)))\n",
    "\n",
    "    # Lift remaining source points and sampled points to 3D\n",
    "    for x in range(len(sampled_points)):\n",
    "        source_points_3d.append(project_2d_to_3d(source_points[1+x], K[0], depth[0][source_points[1+x][::-1]]))\n",
    "        target_points_3d.append(project_2d_to_3d(sampled_points[x], K[1], depth[1][sampled_points[x][::-1]]))\n",
    "\n",
    "    return np.array(source_points_3d), np.array(target_points_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9c2818b-d8f1-407d-855d-a37b2fc28abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_3d_correspondences2(source_points: list, target_points: tuple, depth: list, K: list, max_distance = 3):\n",
    "    source_points_3d = []\n",
    "    target_points_3d = []\n",
    "\n",
    "    for point in source_points:\n",
    "        source_points_3d.append(project_2d_to_3d(point, K[0], depth[0][point[::-1]]))\n",
    "\n",
    "    for point in target_points:\n",
    "        target_points_3d.append(project_2d_to_3d(point, K[1], depth[1][point[::-1]]))\n",
    "\n",
    "    return np.array(source_points_3d), np.array(target_points_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e40a9155-6c3a-4e71-b15f-b81f24a4d791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_point_to_original(resized_point, original_size, resized_size):\n",
    "    \"\"\"\n",
    "    Map a point from the resized image to the original image coordinates.\n",
    "\n",
    "    Args:\n",
    "    - resized_point: Tuple (x, y) representing the coordinates in the resized image.\n",
    "    - original_size: Tuple (original_width, original_height) for the original image size.\n",
    "    - resized_size: Tuple (resized_width, resized_height) for the resized image size.\n",
    "\n",
    "    Returns:\n",
    "    - original_point: Tuple (x, y) representing the mapped coordinates in the original image.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract coordinates\n",
    "    x_resized, y_resized = resized_point\n",
    "    original_width, original_height = original_size\n",
    "    resized_width, resized_height = resized_size\n",
    "    \n",
    "    # Compute the scaling factors\n",
    "    scale_x = original_width / resized_width\n",
    "    scale_y = original_height / resized_height\n",
    "    \n",
    "    # Map the point in the resized image to the original image\n",
    "    x_original = x_resized * scale_x\n",
    "    y_original = y_resized * scale_y\n",
    "    \n",
    "    return (int(x_original), int(y_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7be983b-1707-445d-b906-f577b705cf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_2d_point(point: tuple, original_size: tuple, resized_size: tuple):\n",
    "    return map_point_to_original(point, original_size, resized_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77802d8d-30fe-4c51-83ef-c2b636a25520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_2d_point(original_point, original_size, resized_size):\n",
    "    \"\"\"\n",
    "    Compute the corresponding point in a resized image.\n",
    "    \n",
    "    Args:\n",
    "        original_point (tuple): (x, y) coordinates of the point in the original image.\n",
    "        original_size (tuple): (width, height) of the original image.\n",
    "        resized_size (tuple): (width, height) of the resized image.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (x, y) coordinates of the point in the resized image.\n",
    "    \"\"\"\n",
    "    x, y = original_point\n",
    "    orig_width, orig_height = original_size\n",
    "    resized_width, resized_height = resized_size\n",
    "    \n",
    "    # Scale the point\n",
    "    x_new = x * resized_width / orig_width\n",
    "    y_new = y * resized_height / orig_height\n",
    "    \n",
    "    return (int(x_new), int(y_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25ac4ab-819a-48c1-9f4d-a62e7f883994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "import numpy as np\n",
    "\n",
    "def map_points_to_nearest_pointcloud(pointcloud, points):\n",
    "    \"\"\"\n",
    "    Maps 3D points to their nearest neighbor in a given point cloud.\n",
    "\n",
    "    Args:\n",
    "        pointcloud (np.ndarray): Point cloud as an (N, 3) array of 3D points.\n",
    "        points (np.ndarray): Set of points to map as an (M, 3) array of 3D points.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array of the nearest point cloud points for each input point.\n",
    "    \"\"\"\n",
    "    pointcloud_np = pointcloud\n",
    "    \n",
    "    # Build a KDTree from the point cloud\n",
    "    tree = cKDTree(pointcloud_np)\n",
    "    \n",
    "    # Query the tree for distances and indices of the nearest neighbors\n",
    "    _, indices = tree.query(points)\n",
    "    \n",
    "    # Map input points to their nearest point in the point cloud\n",
    "    nearest_points = pointcloud_np[indices]\n",
    "    \n",
    "    return nearest_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1e4518ec-31b8-416f-b78c-3e9023a36036",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def sanity_check(point: tuple, img):\n",
    "    image = copy.deepcopy(img)\n",
    "    \n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    point = point\n",
    "    radius = 5\n",
    "    color = (255, 0, 0)\n",
    "    \n",
    "    draw.ellipse(\n",
    "        [point[0] - radius, point[1] - radius, point[0] + radius, point[1] + radius],\n",
    "        fill=color\n",
    "    )\n",
    "    \n",
    "    image.save(\"sanity_check.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b020cac3-ad89-4f0c-b0a4-cfc056374492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_3d_distance(point1, point2):\n",
    "    return np.linalg.norm(point1 - point2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "50c2efd9-9792-44ca-96cf-5f1c1821b4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_matches(pc1_np, pc2_np, R, t, threshold=0.02):\n",
    "    \"\"\"\n",
    "    Count the number of matching points after applying a transformation to pc1.\n",
    "    \n",
    "    Args:\n",
    "        pc1 (o3d.geometry.PointCloud): First point cloud (source).\n",
    "        pc2 (o3d.geometry.PointCloud): Second point cloud (target).\n",
    "        R (np.ndarray): Rotation matrix (3x3).\n",
    "        t (np.ndarray): Translation vector (3,).\n",
    "        threshold (float): Distance threshold for matching points.\n",
    "    \n",
    "    Returns:\n",
    "        int: Number of matching points.\n",
    "    \"\"\"\n",
    "    # Apply the transformation\n",
    "    transformed_pc1_np = (R @ pc1_np.T).T + t  # Transform pc1 (broadcast t over rows)\n",
    "    \n",
    "    # Build a KDTree for efficient nearest-neighbor search\n",
    "    tree = cKDTree(pc2_np)\n",
    "    \n",
    "    # Query the KDTree for each point in the transformed point cloud\n",
    "    distances, indices = tree.query(transformed_pc1_np, k=1)\n",
    "    \n",
    "    # Count matches within the distance threshold\n",
    "    num_matches = np.sum(distances < threshold)\n",
    "\n",
    "    return num_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0704a259-fa69-4c47-add4-b06c45546337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_point_cloud(pc):\n",
    "    \"\"\"\n",
    "    Centers an Open3D PointCloud by translating its centroid to the origin.\n",
    "    \n",
    "    Parameters:\n",
    "    - pc (o3d.geometry.PointCloud): The input point cloud to be centered.\n",
    "    \n",
    "    Returns:\n",
    "    - o3d.geometry.PointCloud: A new point cloud centered at the origin.\n",
    "    \"\"\"\n",
    "    # Convert point cloud to numpy array\n",
    "    points = np.asarray(copy.deepcopy(pc.points))\n",
    "\n",
    "    # Compute centroid\n",
    "    centroid = np.mean(points, axis=0)\n",
    "    \n",
    "    # # Subtract the centroid to center the point cloud\n",
    "    # centered_points = points - centroid\n",
    "    \n",
    "    # # Create a new Open3D PointCloud object\n",
    "    # centered_pc = copy.deepcopy(pc)\n",
    "    # centered_pc.points = o3d.utility.Vector3dVector(centered_points)\n",
    "    \n",
    "    # return centered_pc, centroid\n",
    "    return pc, centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b516a2bb-9cba-4f94-a2ac-5439f7b43add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_3d_to_2d(point_3d, K):\n",
    "    \"\"\"\n",
    "    Project a 3D point to 2D using the intrinsic matrix.\n",
    "    \n",
    "    :param point_3d: A numpy array or list of [x, y, z] representing the 3D point.\n",
    "    :param K: Intrinsic matrix of the camera.\n",
    "    :return: A tuple (u, v) representing the 2D image coordinates.\n",
    "    \"\"\"\n",
    "    # Convert the 3D point into homogeneous coordinates\n",
    "    point_3d_homogeneous = np.array([point_3d[0], point_3d[1], point_3d[2], 1.0])\n",
    "    \n",
    "    # Project the 3D point onto the 2D image plane using the intrinsic matrix\n",
    "    point_2d_homogeneous = K @ point_3d[:3]  # Matrix multiplication\n",
    "\n",
    "    # Normalize to get (u, v) image coordinates\n",
    "    u = point_2d_homogeneous[0] / point_2d_homogeneous[2]\n",
    "    v = point_2d_homogeneous[1] / point_2d_homogeneous[2]\n",
    "\n",
    "    return int(u), int(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f3d6ca1-7982-4254-b5b0-744177b5cdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_2d_to_3d(point_2d, K, depth):\n",
    "    \"\"\"\n",
    "    Project a 2D point to 3D given the camera intrinsic matrix and the depth.\n",
    "\n",
    "    :param point_2d: A tuple or list (u, v) representing the 2D image coordinates.\n",
    "    :param K: Camera intrinsic matrix (3x3).\n",
    "    :param depth: The depth (z-value) at the 2D point.\n",
    "    :return: A numpy array [x, y, z] representing the 3D point in camera coordinates.\n",
    "    \"\"\"\n",
    "    u, v = point_2d\n",
    "\n",
    "    # Create the 2D point in homogeneous coordinates\n",
    "    point_2d_homogeneous = np.array([u, v, 1.0])\n",
    "\n",
    "    # Invert the intrinsic matrix\n",
    "    K_inv = np.linalg.inv(K)\n",
    "\n",
    "    # Compute the 3D point in camera coordinates\n",
    "    point_3d = depth * K_inv @ point_2d_homogeneous\n",
    "\n",
    "    return point_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2a5c69d-bf5b-48dd-8240-5f345ecd8591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpy_to_rotation_matrix(roll, pitch, yaw):\n",
    "    \"\"\"\n",
    "    Convert Roll, Pitch, Yaw angles to a rotation matrix.\n",
    "    \n",
    "    Args:\n",
    "        roll (float): Roll angle in radians.\n",
    "        pitch (float): Pitch angle in radians.\n",
    "        yaw (float): Yaw angle in radians.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: 3x3 rotation matrix.\n",
    "    \"\"\"\n",
    "    # Compute individual rotation matrices\n",
    "    R_x = np.array([\n",
    "        [1, 0, 0],\n",
    "        [0, np.cos(roll), -np.sin(roll)],\n",
    "        [0, np.sin(roll), np.cos(roll)]\n",
    "    ])\n",
    "    \n",
    "    R_y = np.array([\n",
    "        [np.cos(pitch), 0, np.sin(pitch)],\n",
    "        [0, 1, 0],\n",
    "        [-np.sin(pitch), 0, np.cos(pitch)]\n",
    "    ])\n",
    "    \n",
    "    R_z = np.array([\n",
    "        [np.cos(yaw), -np.sin(yaw), 0],\n",
    "        [np.sin(yaw), np.cos(yaw), 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    \n",
    "    # Combined rotation matrix: R = Rz * Ry * Rx\n",
    "    R = R_z @ R_y @ R_x\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d90cc857-2949-4171-bcab-bf93aeecf991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pointcloud(pc1, nb_neighbors=50, std_ratio=0.5, voxel_size=0.02):\n",
    "    pcd = copy.deepcopy(pc1)\n",
    "\n",
    "    cl, ind = pcd.remove_statistical_outlier(nb_neighbors=nb_neighbors, std_ratio=std_ratio)\n",
    "    pcd = pcd.select_by_index(ind)\n",
    "    \n",
    "    voxel_size = voxel_size  # Adjust this parameter as needed\n",
    "    pcd = pcd.voxel_down_sample(voxel_size=voxel_size)\n",
    "\n",
    "    pcd, centroid = center_point_cloud(pcd)\n",
    "\n",
    "    return pcd, centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b190d1e-7237-4219-82ae-346e8d062ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pcd_from_rgbd(rgb_image, depth_image, intrinsics):\n",
    "    # Convert numpy arrays to Open3D images\n",
    "    o3d_rgb = o3d.geometry.Image(rgb_image.astype(np.uint8))\n",
    "    o3d_depth = o3d.geometry.Image(depth_image.astype(np.float32))\n",
    "\n",
    "    # Create an RGBDImage from the RGB and depth images\n",
    "    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        color=o3d_rgb,\n",
    "        depth=o3d_depth,\n",
    "        depth_scale=1.0,    # Adjust if depth is not in meters (e.g., if in mm, use 1000.0)\n",
    "        depth_trunc=1000.0, # Maximum depth cut off\n",
    "        convert_rgb_to_intensity=False\n",
    "    )\n",
    "\n",
    "    # Create point cloud from RGBD image and intrinsics\n",
    "    pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_image, intrinsics)\n",
    "\n",
    "    return pcd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d01b51-7f40-4bbd-b3ed-e92f1fee86f5",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8fa81f6-4220-4455-8c89-62e2b61f583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_points(img, points, original_size, resized_size, size=10):\n",
    "    base_image = copy.deepcopy(img)\n",
    "    draw = ImageDraw.Draw(base_image)\n",
    "    \n",
    "    for point in points:\n",
    "        upsampled_point = upsample_2d_point(point, original_size, resized_size)\n",
    "        draw.ellipse((upsampled_point[0] - size, upsampled_point[1] - size, upsampled_point[0] + size, upsampled_point[1] + size), fill=\"red\")\n",
    "        \n",
    "    return base_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07988d06-4adc-43a2-be54-3af95f7af019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_points_on_pointcloud(pc, pc_centroid, points, scaling_factor=1, radius=0.05):\n",
    "    # Step1: Deep copy the input pointcloud\n",
    "    A = copy.deepcopy(pc)\n",
    "    \n",
    "    # Step 2: Define the new points and set their color to red\n",
    "    new_points = np.array(points) * scaling_factor\n",
    "    new_points -= (pc_centroid * scaling_factor)\n",
    "    new_colors = np.array([[1, 0, 0] for point in points])\n",
    "    \n",
    "    # Step 3: Combine the new points with the existing point cloud\n",
    "    combined_points = np.vstack((np.asarray(A.points), new_points))\n",
    "    combined_colors = np.vstack((np.asarray(A.colors), new_colors))\n",
    "    \n",
    "    # Update the original point cloud with combined data\n",
    "    A.points = o3d.utility.Vector3dVector(combined_points)\n",
    "    A.colors = o3d.utility.Vector3dVector(combined_colors)\n",
    "    \n",
    "    # Step 4: Create spheres for the new points to simulate increased size\n",
    "    spheres = []\n",
    "    for point in new_points:\n",
    "        sphere = o3d.geometry.TriangleMesh.create_sphere(radius=radius)  # Adjust the radius for desired size\n",
    "        sphere.translate(point)  # Move sphere to the point location\n",
    "        sphere.paint_uniform_color([1, 0, 0])  # Set color to red\n",
    "        spheres.append(sphere)\n",
    "    \n",
    "    # Combine the point cloud and spheres for visualization\n",
    "    geometry_list1 = [A] + spheres\n",
    "    \n",
    "    # Step 5: Visualize the updated point cloud with enlarged new points\n",
    "    o3d.visualization.draw_geometries(geometry_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1e36446-159f-4364-8f5d-85c9e331ee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def axis_angle_to_rotation_matrix(axis_angle):\n",
    "    \"\"\"\n",
    "    Converts an axis-angle representation to a 3x3 rotation matrix.\n",
    "    \"\"\"\n",
    "    rotation_matrix = R.from_rotvec(axis_angle).as_matrix()\n",
    "    return rotation_matrix\n",
    "\n",
    "def create_frame(position, rotation_matrix, size=0.2):\n",
    "    \"\"\"\n",
    "    Creates a coordinate frame at a specific position and orientation.\n",
    "    \"\"\"\n",
    "    frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=size)\n",
    "    # Apply rotation\n",
    "    frame.rotate(rotation_matrix, center=(0, 0, 0))\n",
    "    # Apply translation\n",
    "    frame.translate(position)\n",
    "    return frame\n",
    "\n",
    "def get_joint_frames(joint_positions, joint_angles):\n",
    "    \"\"\"\n",
    "    Visualizes joint frames with the correct rotations applied.\n",
    "\n",
    "    Args:\n",
    "        joint_positions (np.ndarray): Nx3 array of joint positions.\n",
    "        joint_angles (np.ndarray): Nx3 array of joint axis-angle rotations.\n",
    "    \"\"\"\n",
    "    vis_objects = []\n",
    "    for position, axis_angle in zip(joint_positions, joint_angles):\n",
    "        # Convert axis-angle to rotation matrix\n",
    "        rotation_matrix = axis_angle_to_rotation_matrix(axis_angle)\n",
    "        # Create a coordinate frame for the joint\n",
    "        frame = create_frame(position, rotation_matrix)\n",
    "        vis_objects.append(frame)\n",
    "\n",
    "    return vis_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076d6403-bcc5-4d03-8d21-1d67de029da9",
   "metadata": {},
   "source": [
    "# Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7f40e72-86ca-4b68-b7c7-55ba3b2b51de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_xyz_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Compute the Euclidean distance between two 3D points.\n",
    "    \n",
    "    Parameters:\n",
    "    - point1: array-like, coordinates of the first point (x1, y1, z1).\n",
    "    - point2: array-like, coordinates of the second point (x2, y2, z2).\n",
    "    \n",
    "    Returns:\n",
    "    - distance: float, the Euclidean distance between the points.\n",
    "    \"\"\"\n",
    "    # Convert inputs to numpy arrays for convenience\n",
    "    point1 = np.array(point1)\n",
    "    point2 = np.array(point2)\n",
    "    \n",
    "    # Compute the Euclidean distance\n",
    "    distance = np.linalg.norm(point1 - point2)\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d69e37a7-3868-436c-88e4-42ccbac16dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_xy_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Compute the Euclidean distance between two 3D points in the xy-plane.\n",
    "    \n",
    "    Parameters:\n",
    "    - point1: array-like, coordinates of the first point (x1, y1, z1).\n",
    "    - point2: array-like, coordinates of the second point (x2, y2, z2).\n",
    "    \n",
    "    Returns:\n",
    "    - distance_xy: float, the Euclidean distance in the xy-plane.\n",
    "    \"\"\"\n",
    "    # Extract x and y coordinates\n",
    "    x1, y1 = point1[0], point1[1]\n",
    "    x2, y2 = point2[0], point2[1]\n",
    "    \n",
    "    # Compute the 2D Euclidean distance\n",
    "    distance_xy = np.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "    \n",
    "    return distance_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06c6887e-3496-4905-a134-3d5038c90880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_between_vectors(v1, v2):\n",
    "    \"\"\"\n",
    "    Compute the angle (in radians) between two vectors.\n",
    "    \n",
    "    Parameters:\n",
    "    - v1: array-like, the first vector\n",
    "    - v2: array-like, the second vector\n",
    "    \n",
    "    Returns:\n",
    "    - angle: float, the angle in radians between the two vectors\n",
    "    \"\"\"\n",
    "    # Convert inputs to numpy arrays\n",
    "    v1 = np.array(v1)\n",
    "    v2 = np.array(v2)\n",
    "    \n",
    "    # Compute the dot product and magnitudes\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    magnitude_v1 = np.linalg.norm(v1)\n",
    "    magnitude_v2 = np.linalg.norm(v2)\n",
    "    \n",
    "    # Prevent division by zero\n",
    "    if magnitude_v1 == 0 or magnitude_v2 == 0:\n",
    "        raise ValueError(\"One of the vectors has zero magnitude.\")\n",
    "    \n",
    "    # Compute the cosine of the angle\n",
    "    cos_theta = dot_product / (magnitude_v1 * magnitude_v2)\n",
    "    \n",
    "    # Clip values to handle numerical issues (e.g., slight overflow beyond [-1, 1])\n",
    "    cos_theta = np.clip(cos_theta, -1.0, 1.0)\n",
    "    \n",
    "    # Compute the angle in radians\n",
    "    angle = np.arccos(cos_theta)\n",
    "    \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "631f89d9-a8a4-46c1-b818-d8cdf4ce9cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_smallest_indices(values, n):\n",
    "    \"\"\"\n",
    "    Return the indices of the top N smallest values from a list.\n",
    "    \n",
    "    Parameters:\n",
    "    - values: list of numbers\n",
    "    - n: int, number of smallest values to return\n",
    "    \n",
    "    Returns:\n",
    "    - list: Indices of the top N smallest values in ascending order of value.\n",
    "    \"\"\"\n",
    "    # Use heapq.nsmallest with indices\n",
    "    return [idx for value, idx in heapq.nsmallest(n, [(v, i) for i, v in enumerate(values)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8986d57b-6221-4535-85e3-11bd7a1f8675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chamfer_distance(pcd1, pcd2, R, t) -> float:\n",
    "    \"\"\"\n",
    "    Compute the Chamfer Distance between two Open3D PointClouds.\n",
    "\n",
    "    Parameters:\n",
    "        pcd1 (o3d.geometry.PointCloud): First point cloud.\n",
    "        pcd2 (o3d.geometry.PointCloud): Second point cloud.\n",
    "\n",
    "    Returns:\n",
    "        float: Chamfer distance between the two point clouds.\n",
    "    \"\"\"\n",
    "    # Extract points from the point clouds as numpy arrays\n",
    "    points1 = np.asarray(pcd1.points)\n",
    "    points2 = np.asarray(pcd2.points)\n",
    "\n",
    "    # Transform point1\n",
    "    transformed_points1 = (R @ points1.T).T + t\n",
    "\n",
    "    # Build KD-Trees for efficient nearest neighbor search\n",
    "    tree1 = cKDTree(transformed_points1)\n",
    "    tree2 = cKDTree(points2)\n",
    "\n",
    "    # Compute the nearest neighbor distances from points1 to points2\n",
    "    dist1, _ = tree1.query(points2)\n",
    "    dist2, _ = tree2.query(points1)\n",
    "\n",
    "    # Chamfer distance: mean of the nearest neighbor distances\n",
    "    chamfer_dist = np.mean(dist1**2) + np.mean(dist2**2)\n",
    "\n",
    "    return chamfer_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c873bb78-0c4a-4171-8783-fa41cc5d4c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_top_matches(cos_map, n_points, min_distance=50):\n",
    "    \"\"\"\n",
    "    Select top points from a cosine similarity map with a constraint that they are at least\n",
    "    a minimum distance apart based on a distance metric.\n",
    "    \n",
    "    Args:\n",
    "        cos_map (np.ndarray): Cosine similarity map of shape (1, height, width).\n",
    "        min_distance (float): Minimum distance between selected points.\n",
    "\n",
    "    Returns:\n",
    "        list: List of selected points (x, y) that satisfy the constraints.\n",
    "    \"\"\"\n",
    "    # Parameters\n",
    "    select = n_points\n",
    "    top_n = 5000\n",
    "    \n",
    "    # Step 1: Flatten the map and get indices of top points\n",
    "    flat_cos_map = cos_map[0].ravel()\n",
    "    top_indices = np.argpartition(flat_cos_map, -top_n * 10)[-top_n * 10:]\n",
    "    top_indices_sorted = top_indices[np.argsort(flat_cos_map[top_indices])[::-1]]\n",
    "    \n",
    "    # Step 2: Convert indices back to 2D coordinates\n",
    "    top_xy_candidates = np.array(np.unravel_index(top_indices_sorted, cos_map[0].shape)).T[:, ::-1]\n",
    "    \n",
    "    # Step 3: Select points based on distance constraint\n",
    "    selected_ref_points = []\n",
    "    \n",
    "    for candidate in top_xy_candidates:\n",
    "        if len(selected_ref_points) == 0:\n",
    "            selected_ref_points.append(candidate)\n",
    "        else:\n",
    "            # Calculate distances from the candidate to all previously selected points\n",
    "            distances = cdist([candidate], selected_ref_points)\n",
    "            if np.all(distances >= min_distance):\n",
    "                # Optional: Check if candidate satisfies other conditions (e.g., masks_target)\n",
    "                selected_ref_points.append(candidate)\n",
    "            \n",
    "            # Stop once we've collected enough points\n",
    "            if len(selected_ref_points) >= select:\n",
    "                break\n",
    "    \n",
    "    return selected_ref_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22635089-1f42-4202-835b-f2bea6bee738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_rotation_matrix():\n",
    "    \"\"\"\n",
    "    Generate a random 3x3 rotation matrix.\n",
    "    A rotation matrix is an orthogonal matrix with determinant 1.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A 3x3 rotation matrix.\n",
    "    \"\"\"\n",
    "    # Generate a random 3x3 matrix\n",
    "    random_matrix = np.random.randn(3, 3)\n",
    "    \n",
    "    # Perform QR decomposition\n",
    "    q, r = np.linalg.qr(random_matrix)\n",
    "    \n",
    "    # Ensure the determinant is 1 for a proper rotation matrix\n",
    "    if np.linalg.det(q) < 0:\n",
    "        q[:, 2] = -q[:, 2]\n",
    "    \n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cbfcd9a-c76a-4b98-a073-1a0c7c6e8e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rotation_to_pointcloud(point_cloud, rotation_matrix):\n",
    "    \"\"\"\n",
    "    Applies a rotation matrix to an Open3D point cloud.\n",
    "\n",
    "    Args:\n",
    "        point_cloud (o3d.geometry.PointCloud): The input point cloud.\n",
    "        rotation_matrix (numpy.ndarray): The 3x3 rotation matrix to apply.\n",
    "\n",
    "    Returns:\n",
    "        o3d.geometry.PointCloud: The rotated point cloud.\n",
    "    \"\"\"\n",
    "    # Get the numpy array of points from the point cloud\n",
    "    points = np.asarray(point_cloud.points)\n",
    "    \n",
    "    # Apply the rotation matrix to the points\n",
    "    rotated_points = np.dot(points, rotation_matrix)\n",
    "    \n",
    "    # Create a new point cloud with rotated points\n",
    "    rotated_point_cloud = o3d.geometry.PointCloud()\n",
    "    rotated_point_cloud.points = o3d.utility.Vector3dVector(rotated_points)\n",
    "    \n",
    "    # Preserve colors if present\n",
    "    if point_cloud.has_colors():\n",
    "        rotated_point_cloud.colors = point_cloud.colors\n",
    "    \n",
    "    return rotated_point_cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23baf81-d241-41b3-aac0-29e5835487b5",
   "metadata": {},
   "source": [
    "# OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b131f83-5ec3-4ed7-9b19-a575cc92f07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_corners(image, mask, max_corners=1000, quality_level=0.01, min_distance=10, plot=False):\n",
    "    \"\"\"\n",
    "    Computes corners in the image within a specified mask using Shi-Tomasi Corner Detector.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): Input image.\n",
    "        mask (np.ndarray): Binary mask where the corners are to be detected.\n",
    "        max_corners (int): Maximum number of corners to detect.\n",
    "        quality_level (float): Minimum accepted quality of corners.\n",
    "        min_distance (float): Minimum possible Euclidean distance between the returned corners.\n",
    "        plot (bool): Whether to plot the image with detected corners.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Detected corners within the masked region.\n",
    "    \"\"\"\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect corners using Shi-Tomasi Corner Detector\n",
    "    corners = cv2.goodFeaturesToTrack(gray_image, max_corners, quality_level, min_distance, mask=mask)\n",
    "    \n",
    "    if corners is not None:\n",
    "        corners = np.int0(corners)  # Convert to integer for pixel indexing\n",
    "    \n",
    "        # Filter corners by the mask\n",
    "        filtered_corners = []\n",
    "        for corner in corners:\n",
    "            x, y = corner.ravel()\n",
    "            if mask[y, x]:  # Check if the corner is within the masked region\n",
    "                filtered_corners.append((x, y))\n",
    "        \n",
    "    #     filtered_corners = np.array(filtered_corners)\n",
    "    # else:\n",
    "    #     filtered_corners = np.array([])  # No corners found\n",
    "\n",
    "    if plot:\n",
    "        # Draw circles on the detected corners within the mask\n",
    "        image_with_corners = image.copy()\n",
    "        for corner in filtered_corners:\n",
    "            x, y = corner\n",
    "            cv2.circle(image_with_corners, (x, y), 5, (0, 255, 0), -1)  # Draw green circles\n",
    "        \n",
    "        # Display the original image with corners\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.title(\"Detected Corners in Masked Region\")\n",
    "        plt.imshow(cv2.cvtColor(image_with_corners, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for display\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return filtered_corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f53275c-86b3-40d7-b094-d70099ea0aca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
